---
title: "Analysis for: Satellites reveal global extent of forced labor in the worldâ€™s fishing fleet"
author: "Gavin McDonald - Environmental Market Solutions Lab (emLab)"
date: '`r format(Sys.time(), "%m/%d/%Y")`'
output: 
  pdf_document: 
    toc: yes
editor_options: 
  chunk_output_type: console
params:
     run_analysis: FALSE
     run_robustness: FALSE
     generate_figures: FALSE
     use_big_query: FALSE
---

```{r echo = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.height=7.5, fig.width=7.5,eval=FALSE)
```

```{r eval = TRUE}
set.seed(101)
# Load Necessary libraries
library(tidyverse)
library(tidymodels)
library(ranger)
library(kernlab)
library(tictoc)
library(workflows)
library(countrycode)
library(bigrquery)
library(sf)
library(here)
library(rworldmap)
library(ggforce)
library(anonymizer)
library(cowplot)
library(kableExtra)
```

# Analysis

```{r eval = (params$run_analysis | params$generate_figures)}
# Load custom threshold_perf function, adapted from probably::threshold_perf to give different metrics
source(here::here("r/threshold_perf_custom.R"))

# Set data directory based on system
# This references the emLab shared Team Drive
# This directory will be used for cacheing large results, as well as results from portions of the analysis that take a long time to run
# Note that for this analysis to be completely re-run, the user should specify an appropriate data directory. Otherwise, the most important cached data for reproducing the figures and statistics in the paper can be found within the GitHub repo itself.
data_directory <- ifelse(Sys.info()["sysname"]=="Windows","G:/Shared\ drives/emLab/Projects/current-projects/forced-labor-and-fisheries/data/phase-1",
                         "/Volumes/GoogleDrive/Shared\ drives/emLab/Projects/current-projects/forced-labor-and-fisheries/data/phase-1")

# Read in cached data
main_df <- read_csv(here::here("raw_data/s1_training_full.csv")) %>%
  filter(!is.na(flag)) %>%
  # Only include gears for which we have known offenders
  filter(gear %in% c("drifting_longlines","squid_jigger","trawlers")) %>%
  # Make binaries into 1s/0s
  mutate(offender = ifelse(offender,1,0),
         foc = ifelse(foc,1,0),
         iuu = ifelse(iuu,1,0)) 

# Select only possible vessel years
# Only classify known offenders as positive in the year prior to being caught
positive_vessels <- main_df %>%
  filter(offender == 1 & years_until_caught == 1) %>%
  dplyr::select(mmsi,fldb_vessel_id,year,offender)

filtered_main_df <- main_df %>%
  # Only only include vessel-years from positives in the year prior to being caught
  # Otherwise exclude them from training - they have high potential for being positive
  dplyr::select(-fldb_vessel_id,-offender) %>%
  left_join(positive_vessels,by=c("mmsi","year")) %>%
  filter(!(mmsi %in% positive_vessels$mmsi & !offender)) %>%
  dplyr::select(-years_until_caught) %>%
  # Make binaries into 1s/0s
  mutate(offender = ifelse(is.na(offender),0,1),
         foc = ifelse(foc,1,0),
         iuu = ifelse(iuu,1,0))

training_df <- filtered_main_df %>%
  # Add media source id
  # If it's not a known offender, create dummy ID for CV
  mutate(source_id = ifelse(offender != 1,
                            paste0("no_source_",row_number()),
                            source_id)) %>%
  # Add forced labor database vessel id
  # If it's not a known offender, create dummy ID for CV
  mutate(fldb_vessel_id = ifelse(offender != 1,
                            paste0("no_fldb_info_",row_number()),
                            fldb_vessel_id)) %>%
  # Make these columns factors
  mutate_at(
     vars("foc", "iuu", "gear", "flag", "year", "ais_type", "mmsi", "fldb_vessel_id", "year", "source_id", "offender"),
     list(as.factor)) 

prediction_df <- main_df %>%
  dplyr::select(-fldb_vessel_id,-offender) %>%
  # Attach positive fldb_vessel_id to MMSIs, so we can see how these change over time
  left_join(positive_vessels %>% dplyr::select(-year),by=c("mmsi")) %>%
  mutate(offender = case_when(offender == 1 & years_until_caught == 1 ~ 1,
                              is.na(offender) ~ 0,
                              TRUE ~ 0)) %>%
  dplyr::select(-years_until_caught) %>%
  # Make these columns factors
  mutate_at(
     vars("foc", "iuu", "gear", "flag", "year", "ais_type", "mmsi", "fldb_vessel_id", "year", "source_id", "offender"),
     list(as.factor))

# Read in feature lookup table
feature_lookup <- read_csv(here::here("raw_data/s2_feature_lookup.csv"))
```

```{r}
# Recipe for processing data within each sampling iteration
fl_rec <- recipes::recipe(offender ~ ., data = head(training_df)) %>%
  recipes::update_role(mmsi, new_role = "id variable") %>%
  recipes::update_role(fldb_vessel_id, new_role = "id variable") %>%
  recipes::update_role(source_id, new_role = "id variable") %>%
  # Downsample unlabaled vessels
  # Skip=TRUE so that the testing dataset is not downsampled when baking
  # Do this at random every time
  #recipes::step_downsample("offender",under_ratio = tune(),skip=TRUE)  %>%
  recipes::step_knnimpute(ais_type,impute_with = c("gear","flag","length_m")) %>%
  # Box-Cox transformation on all numeric
  recipes::step_BoxCox(all_numeric()) %>%
  # Group flags with less than 1% into other
  recipes::step_other(flag, threshold = 0.01) %>%
  # Create dummy variables for factor columns like flag, ais_type
  recipes::step_dummy(all_predictors(), -all_numeric()) %>%
  # Remove near-zero variance numeric predictors
  recipes::step_nzv(all_predictors()) %>%
  # Remove numeric predictors that have correlation greater the 75%
  recipes::step_corr(all_numeric(), threshold = 0.75) %>%
  # Center all numeric predictors
  recipes::step_center(all_numeric()) %>%
  # Scale all numeric predictors
  recipes::step_scale(all_numeric())
```

```{r}
# Define model specs
# Random forest
# Use default hyperparameters
rf_mod <- rand_forest(
  mode = "classification",
  trees = 1000
) %>%
  set_engine("ranger")

# SVM
# Use default hyperparameters
svm_mod <- svm_rbf(mode = "classification") %>%
  set_engine("kernlab",scaled=FALSE)
```

```{r}
# Cross-validation
# Ensure there is no splitting across source_id (and consequently fldb_vessel_id) across analysis and assessment datasets
set.seed(101)
cv_splits <- group_vfold_cv(training_df, 
                            group = source_id,
                            v = 10)

# NA means no downsampling, so just the regular base classifier
under_ratio_vec <- tibble(under_ratio = c(NA,seq(1,5)))
# Number of bags
bag_vec <- tibble(bag = seq(100))
# Different models to try
model_type_vec <- tibble(model_type = c("random-forest","svm"))

analysis_data <- cv_splits %>%
  mutate(# Create analysis dataset based on CV folds
    analysis = map(splits,~analysis(.x)),
    # Create assessment dataset based on CV folds
    assessment = map(splits,~assessment(.x))) %>%
  dplyr::select(-splits)

model_runs <- crossing(under_ratio_vec,
                       model_type_vec,
           bag_vec) %>%
  # If there's no downsampling, there's no bagging
  mutate(bagging = ifelse(is.na(under_ratio),FALSE,TRUE)) %>%
  # Don't need to bag if not doing downsampling
  filter(!(!bagging & bag >1)) %>%
  # Want different seed each time downsampling is done, for bagging
  mutate(seed = sample.int(10^5,n()))

pb <- progress_estimated(nrow(model_runs) * nrow(cv_splits))

predictions <- model_runs %>%
  mutate(recipe = map2(seed,bagging,function(x,y){
    # Add downsampling to pre-processing recipe if bagging
    ifelse(!y,
           tmp_recipe <- fl_rec,
           tmp_recipe <- fl_rec %>%
             step_downsample("offender",under_ratio=y,seed=x,skip=TRUE))
    return(tmp_recipe)
    # Create workflow based on random forest hyperparameter and downsampling pre-processing recipe
  }),
  workflow = map2(recipe,model_type,function(x,y){
    # Add either random forest or svm to worflow, along with appropriate recipe
    ifelse(y == "random-forest",
           tmp_workflow <- workflow() %>%
             add_model(rf_mod) %>%
             add_recipe(x),
           tmp_workflow <- workflow() %>%
             add_model(svm_mod) %>%
             add_recipe(x))
    return(tmp_workflow)
  })) %>%
  # Remove unnecessary columns
  dplyr::select(-seed,-recipe) %>%
  # For each workflow, do entire model fitting process across all folds
  mutate(predict = map(workflow,function(x){
    analysis_data %>%
      mutate(predict = map2(analysis,assessment,function(y,z){
        tmp <- fit(x,y) %>%
          # Predict assessment data using fit
          predict(z, type = "prob") %>%
          # Add predictions to assessment data
          bind_cols(z) %>%
          # Select relevant columns
          dplyr::select(mmsi,year,offender,.pred_1)
        # Increment progress bar
        pb$tick()$print()
        return(tmp)
      })) %>%
      dplyr::select(id,predict) %>%
      unnest(predict)
  })) %>%
  dplyr::select(-workflow) %>%
  unnest(predict)

# Cache CV results
write_csv(predictions,paste0(data_directory,"/tidy_cv_predictions.csv"))
```

```{r}
# Load cached CV results
predictions <- read_csv(paste0(data_directory,"/tidy_cv_predictions.csv"))
bags_to_show <- c(1,10,50,100)
bag_performance <- map_df(bags_to_show,function(x){
  tmp_performance <- predictions %>%
    filter(bag<=x) %>%
    # For each fold and hyperparameter set, take average prediction for each vessel-year (mmsi and year) across bags
    group_by(id,model_type,under_ratio,mmsi,year) %>%
    summarize(offender = offender[1],
              .pred_1 = mean(.pred_1,na.rm=TRUE)) %>%
    ungroup()  %>%
  # Make offender =1 reference level
  mutate(offender = relevel(as.factor(offender),"1")) %>%
    # Then we will calculate performance metrics, by threshold, for each fold and hyperparameter set
    group_by(id,model_type,under_ratio) %>%
    nest() %>%
    ungroup() %>%
    # Calculated metrics will include recall, modified_f1, and detection_prevalence
    mutate(threshold_perf = map(data,~threshold_perf_custom(.x,
                                                            truth = offender,
                                                            estimate = .pred_1,
                                                            thresholds=seq(0.01,0.99,0.01)))) %>%
    dplyr::select(-data) %>%
    unnest(threshold_perf) %>%
    # Now for each hyperparameter set, we will take the average performance across all folds
    group_by(model_type,under_ratio,.threshold,.metric) %>%
    summarize(mean_performance = mean(.estimate,na.rm=TRUE),
              sd_performance = sd(.estimate,na.rm=TRUE)) %>%
    ungroup() %>%
    group_by(model_type,under_ratio) %>%
    nest() %>%
    ungroup() %>%
    # Now we will find the optimial threshold for maximizing the modified F1 estimator
    # Maximize the mean
    mutate(optimal_threshold = map_dbl(data,~.x %>%
                                         filter(.metric=="modified_f1") %>%
                                         arrange(desc(mean_performance)) %>%
                                         slice(1) %>%
                                         .$.threshold),
           # optimized_metrics will contain metrics with optimized modified F1 estimator
           optimized_metrics = map2(data,optimal_threshold,~.x %>%
                                      filter(.threshold==.y))) %>% 
    unnest(optimized_metrics) %>%
    dplyr::select(-optimal_threshold,-data) %>%
    mutate(number_bags = x)
  print(paste(x,"complete"))
  tmp_performance
})
# Save bag performance estimates for later
write_csv(bag_performance,paste0(data_directory,"/tidy_cv_bag_performance.csv"))
write_csv(bag_performance,here::here("interim_data/s7_figure_s3_data.csv"))
```

```{r}
# Here we choose the optimzed model
# Non-bagging version has standard error too large
# Stick with 5 bags to reduce variation
# Stick with under_ratio of 1 for simplest model
# Random forest has lowest standard deviation for modified f1, and has a higher recall
optimized_model <- tibble(model_type = "random-forest",
                          bagging = TRUE,
                          under_ratio = 1,
                          number_bags = 100)

cv_performance <- bag_performance %>% 
  mutate(bagging = ifelse(is.na(under_ratio),FALSE,TRUE)) %>%
  inner_join(optimized_model,by = c("model_type", "number_bags", "under_ratio","bagging"))

optimized_model$.threshold <- cv_performance$.threshold[1]
```

```{r}
# Train final model on full dataset
set.seed(101)
# Define all model runs
model_runs_final <- optimized_model %>%
  crossing(tibble(bag = seq(optimized_model$number_bags))) %>%
  mutate(seed = sample.int(10^5,n()))

pb <- progress_estimated(nrow(model_runs_final))

predictions_final <- model_runs_final %>%
  mutate(recipe = map2(seed,bagging,function(x,y){
    # Add downsampling to pre-processing recipe if bagging
    ifelse(!y,
           tmp_recipe <- fl_rec,
           tmp_recipe <- fl_rec %>%
             step_downsample("offender",under_ratio=y,seed=x,skip=TRUE))
    return(tmp_recipe)
    # Create workflow based on random forest hyperparameter and downsampling pre-processing recipe
  }),
  workflow = map2(recipe,model_type,function(x,y){
    # Add either random forest or svm to worflow, along with appropriate recipe
    ifelse(y == "random-forest",
           tmp_workflow <- workflow() %>%
             add_model(rf_mod %>%
             set_args(importance = "impurity_corrected")) %>%
             add_recipe(x),
           tmp_workflow <- workflow() %>%
             add_model(svm_mod) %>%
             add_recipe(x))
    return(tmp_workflow)
  })) %>%
  # Remove unnecessary columns
  dplyr::select(-seed,-recipe) %>%
  # For each workflow, do entire model fitting process across all folds
  mutate(fit = map(workflow,~fit(.x,training_df)),
         predict = map(fit,function(x){
           tmp <- x %>%
             # Predict assessment data using fit
             predict(prediction_df, type = "prob") %>%
             # Add predictions to assessment data
             bind_cols(prediction_df)%>%
             # Select relevant columns
             dplyr::select(mmsi,year,offender,.pred_1)
           # Increment progress bar
           pb$tick()$print()
           return(tmp)
         })) %>%
  dplyr::select(-workflow)

saveRDS(predictions_final,paste0(data_directory,"/predictions_final.Rdata"))

as.numeric.factor <- function(x) {as.numeric(levels(x))[x]}
predictions_figures <- predictions_final %>%  
  dplyr::select(-fit) %>%
  unnest(predict) %>%
  # Switch factors to numeric for faster computation, then switch back
  mutate(offender = as.numeric.factor(offender),
         mmsi = as.numeric.factor(mmsi),
         year = as.numeric.factor(year)) %>%
    # Take average prediction for each vessel-year (mmsi and year) across bags
    group_by(mmsi,year) %>%
    summarize(offender = offender[1],
              .pred_1 = mean(.pred_1,na.rm=TRUE)) %>%
    ungroup() %>% 
  mutate(mmsi = as.factor(mmsi),
         year = as.factor(year)) %>%
  left_join(prediction_df %>%
              dplyr::select(-offender),
            by=c("mmsi","year")) %>%
  mutate(Country = countrycode(flag,"iso3c","country.name"))%>%
  # Use optimal threshold found above
  mutate(class = ifelse(.pred_1 >optimized_model$.threshold,1,0))%>% 
  mutate(Prediction = ifelse(class == 1,"Positive","Negative")) %>%
  mutate(Label = ifelse(offender == 0,"Unlabeled","Positive"))

# Save final predictions with MMSI
# This will late be uploaded to BQ, and MMSI will be used to match vessel with fishing activity and port visits
write_csv(predictions_figures,here::here("interim_data/s4_final_model_predictions_private.csv"))
# Save final predictions without MMSI, for public release
write_csv(predictions_figures %>%
            mutate(mmsi_anonymous = anonymize(mmsi),.seed=101) %>%
            dplyr::select(-mmsi),here::here("interim_data/s4_final_model_predictions.csv"))


# Get average variable importance across bags

importance_data <- predictions_final %>%
  mutate(var_imp = map(fit,function(x){
    x$fit$fit$fit$variable.importance%>%
          as.data.frame() %>%
          rownames_to_column() %>%
          `colnames<-`(c("Feature", "Importance"))
  })) %>%
  dplyr::select(bag,var_imp) %>%
  unnest(var_imp) %>%
  group_by(Feature) %>%
  summarize(Importance=mean(Importance,na.rm=TRUE)) %>%
  ungroup() %>%
  left_join(feature_lookup %>%
              rename(Feature = indicator),by="Feature") %>%
  mutate(indicator_name = case_when(Feature == "gear_squid_jigger" ~ "Squid jigger",
                                    Feature == "gear_drifting_longlines" ~ "Longliner",
                                    Feature == "gear_trawlers" ~ "Trawler",
                                    Feature == "ais_type_A" ~ "AIS device type A",
                                    Feature == "ais_type_B" ~ "AIS device type B",
                                    Feature == "flag_other" ~ "Flag: Other",
                                    str_detect(Feature,"year") ~ paste0("Year: ", str_extract(Feature,"(\\d)+")),
                                    str_detect(Feature,"flag") ~ paste0("Flag: ", countrycode(word(Feature, 2, sep = "_"),"iso3c","country.name")),
                                    TRUE ~ indicator_name)) 
# Save data for figure 4
write_csv(importance_data,here::here("interim_data/s8_figure_s5_data.csv"))
```



\pagebreak

# Use BigQuery

In this section, we upload vessel-level risk predictions from the analysis (using the base set of assumptions) to Google BigQuery. Using this information and matching it with spatial fishing effort and port visit information from Global Fishing Watch, we then download spatial forced labor risk fishing effort data and forced labor risk port visit data. **Note:** This section can only be run with proper authentication credentials for accessing specific tables in Global Fishing Watch's BigQuery project.

```{r eval = params$use_big_query}
# Bigquery project
ucsb_project <- "ucsb-gfw"
# Use GFW account, but only for this project
gfw_project <- "world-fishing-827"
options(scipen = 20)
```


## High risk fishing effort  

```{r eval = params$use_big_query}
# Upload risk predictions
# This uses the private version of the file that has actual MMSIs
predictions_figures_private <- read.csv(here::here("interim_data/s4_final_model_predictions_private.csv"),stringsAsFactors = FALSE) %>%
  as_tibble() %>%
  dplyr::select(mmsi,year,gear,offender,fldb_vessel_id,prediction=.pred_1,class,crew_size,flag,Country)


bq_table(project = ucsb_project,table = "risk_predictions",dataset = "human_rights") %>%
  bq_table_upload(values = predictions_figures_private,
                  fields = as_bq_fields(predictions_figures_private),
                  write_disposition = "WRITE_TRUNCATE")

sql<-"SELECT
  mmsi,
  EXTRACT(YEAR
  FROM
    timestamp) year,
  FLOOR(lat / 0.25) * 0.25 + 0.125 lat_bin,
  FLOOR(lon / 0.25) * 0.25 + 0.125 lon_bin,
  SUM((CASE
        WHEN nnet_score2 = 1 AND NOT (distance_from_shore_m < 1000 AND speed < 1) THEN hours
      ELSE
      0
    END
      )) fishing_hours
FROM
  `ucsb-gfw.human_rights.all_vessel_positions`
GROUP BY
  mmsi,
  lat_bin,
  lon_bin,
  year"

# Only run this once since it's so expensive
#bq_project_query(gfw_project,sql, destination_table = bq_table(project = ucsb_project,table = "binned_fishing_base",dataset = "human_rights"),use_legacy_sql = FALSE, allowLargeResults = TRUE,write_disposition = "WRITE_TRUNCATE")

sql <- "#standardSQL
WITH
  fishing_info AS(
  SELECT
    *
  FROM
    `ucsb-gfw.human_rights.binned_fishing_base`),
  extra_offsetting_filter AS(
  SELECT
    CAST(ssvid AS INT64) mmsi,
    year,
    TRUE extra_offsetting
  FROM
    `ucsb-gfw.human_rights.extra_offsetting_filter` ),
  vessel_info AS(
  SELECT
    mmsi,
    year,
    gear,
    flag,
    engine_power_kw
  FROM
    `ucsb-gfw.human_rights.vessel_info_all`),
  risk AS(
  SELECT
    mmsi,
    year,
    class,
    offender
  FROM
    `ucsb-gfw.human_rights.risk_predictions`),
  joined AS(
  SELECT
    *
  FROM
    vessel_info
  LEFT JOIN
    fishing_info
  USING
    (mmsi,
      year)
  LEFT JOIN
    risk
  USING
    (mmsi,
      year)
  LEFT JOIN
    extra_offsetting_filter
  USING
    (mmsi,
      year)
  WHERE extra_offsetting IS NULL)
SELECT
  year,
  gear,
  flag,
  lat_bin,
  lon_bin,
  SUM(fishing_hours) fishing_hours,
  SUM(fishing_hours * offender) known_offender_fishing_hours,
  SUM(fishing_hours * class) at_risk_fishing_hours,
  SUM(fishing_hours * engine_power_kw) fishing_kW_hours,
  SUM(fishing_hours * offender * engine_power_kw) known_offender_fishing_kW_hours,
  SUM(fishing_hours * class * engine_power_kw) at_risk_fishing_kW_hours
FROM
  joined
GROUP BY
  year,
  gear,
  flag,
  lat_bin,
  lon_bin"

bq_project_query(gfw_project,sql, destination_table = bq_table(project = ucsb_project,table = "grouped_fishing_info_predicted",dataset = "human_rights"),use_legacy_sql = FALSE, allowLargeResults = TRUE,write_disposition = "WRITE_TRUNCATE")

sql <- "#standardSQL
  WITH base AS(
  SELECT
    year,
    gear,
    FLOOR(lat_bin / 0.5) * 0.5 + 0.25 lat_bin,
    FLOOR(lon_bin / 0.5) * 0.5 + 0.25 lon_bin,
    fishing_kW_hours,
    at_risk_fishing_kW_hours,
    known_offender_fishing_kW_hours
  FROM
    `ucsb-gfw.human_rights.grouped_fishing_info_predicted`
  WHERE
    fishing_kW_hours > 0)
SELECT
  year,
  gear,
  lat_bin,
  lon_bin,
  SUM(fishing_kW_hours) fishing_kW_hours,
  SUM(at_risk_fishing_kW_hours) at_risk_fishing_kW_hours,
  SUM(known_offender_fishing_kW_hours) known_offender_fishing_kW_hours,
  SUM(known_offender_fishing_kW_hours) / SUM(fishing_kW_hours) fraction_known_offender_fishing_kW_hours,
  SUM(at_risk_fishing_kW_hours) / SUM(fishing_kW_hours) fraction_at_risk_fishing_kW_hours
FROM
  base
WHERE
  gear IN('drifting_longlines',
    'trawlers',
    'squid_jigger')
GROUP BY
  year,
  gear,
  lat_bin,
  lon_bin"

grouped_messages <- bq_project_query(gfw_project, sql) %>%
  bq_table_download(max_results = Inf)

write_csv(grouped_messages %>%
            filter(year==2018) %>%
            dplyr::select(-known_offender_fishing_kW_hours,
                  -fraction_known_offender_fishing_kW_hours) ,path=here::here("interim_data/s5_figure_3_data.csv"))
```

\pagebreak

## High risk port visits

```{r eval = params$use_big_query}
## Port mapping
sql<-"#standardSQL
WITH
  anchorage_ids AS(
  SELECT
    s2id anchorage_id,
    iso3 port_iso3
  FROM
    `world-fishing-827.gfw_research.named_anchorages` ),
  port_visits AS(
  SELECT
    CAST(ssvid AS INT64) mmsi,
    EXTRACT(YEAR
    FROM
      trip_start) year,
    trip_start_anchorage_id anchorage_id
  FROM
    `world-fishing-827.gfw_research.vessel_voyages_v20190722`
  UNION ALL (
    SELECT
      CAST(ssvid AS INT64) mmsi,
      EXTRACT(YEAR
      FROM
        trip_start) year,
      trip_end_anchorage_id anchorage_id
    FROM
      `world-fishing-827.gfw_research.vessel_voyages_v20190722`) )
SELECT
  *
FROM
  port_visits
LEFT JOIN
  anchorage_ids
USING
  (anchorage_id)"

bq_project_query(gfw_project,sql, destination_table = bq_table(project = ucsb_project,table = "port_visits",dataset = "human_rights"),use_legacy_sql = FALSE, allowLargeResults = TRUE,write_disposition = "WRITE_TRUNCATE")

sql <- "WITH
  port_base AS(
  SELECT
    *
  FROM
    `ucsb-gfw.human_rights.port_visits`
  WHERE
    year < 2019),
  risk_predictions AS(
  SELECT
    class,
    offender,
    gear,
    year,
    mmsi
  FROM
    `ucsb-gfw.human_rights.risk_predictions`),
  psma AS(
  SELECT
    iso3 port_iso3,
    EXTRACT(YEAR
    FROM
      date_poc) psma_year
  FROM
    `ucsb-gfw.human_rights.foc_poc_database` ),
  joined AS(
  SELECT
    *
  FROM
    port_base
  JOIN
    risk_predictions
  USING
    (mmsi,
      year)),
  final AS(
  SELECT
    year,
    gear,
    port_iso3,
    COUNT(*) total_visits,
    SUM(class) high_risk_visits,
    SUM(offender) known_offender_visits,
    SUM(class) / COUNT(*) fraction_high_risk_visits
  FROM
    joined
  GROUP BY
    year,
    gear,
    port_iso3)
SELECT
  *,
IF
  (psma_year IS NULL
    OR year < psma_year,
    FALSE,
    TRUE) psma_country
FROM
  final
LEFT JOIN
  psma
USING
  (port_iso3)"

bq_project_query(gfw_project,sql, destination_table = bq_table(project = ucsb_project,table = "port_visits_risk_grouped",dataset = "human_rights"),use_legacy_sql = FALSE, allowLargeResults = TRUE,write_disposition = "WRITE_TRUNCATE")

sql <- "SELECT *
  FROM
    `ucsb-gfw.human_rights.port_visits_risk_grouped`"

port_data <- bq_project_query(gfw_project, sql) %>%
  bq_table_download(max_results = Inf)

write_csv(port_data,path=here::here("interim_data/s6_figure_4_data.csv"))
```

## Time at sea statistic

This query generates the fraction of total time at sea by included vessels in the analysis. By running this query, we find that "These vessels represent 33% of the total time at sea spent by all fishing vessels operating in this time period tracked by Global Fishing Watch."

```{r eval = params$use_big_query}
sql<-"WITH
included_vessels AS(
SELECT
year,mmsi,TRUE included
FROM
`ucsb-gfw.human_rights.risk_predictions`
),
base AS(
SELECT
  CAST(ssvid AS INT64) mmsi,year,
  activity.active_hours active_hours
FROM
  `world-fishing-827.gfw_research.vi_ssvid_byyear_v20190430`
  WHERE on_fishing_list_best),
joined AS(
 SELECT
mmsi,
year,
active_hours,
IF(included,TRUE,FALSE) included
FROM
base
LEFT JOIN
included_vessels
USING(mmsi,year)),
summary AS(
SELECT
SUM(active_hours) active_hours,
included
FROM joined
GROUP BY
included)
SELECT
(SELECT active_hours FROm summary WHERE included)/((SELECT active_hours FROm summary WHERE NOT included)+(SELECT active_hours FROm summary WHERE included)) fraction_active_hours_included"

fraction_active_hours_included <- bq_project_query(gfw_project, sql) %>%
  bq_table_download(max_results = Inf)
```

## Known registry vessel characteristics

```{r eval = params$use_big_query}
# Plot how many vessels have known vessel characteristics, by year
sql<-"
WITH
  risk_predictions AS(
  SELECT
    *
  FROM
    `ucsb-gfw.human_rights.risk_predictions` ),
  known_info AS(
  SELECT
    CAST(ssvid AS INT64) mmsi,
    year,
  IF
    (registry_info.best_known_length_m IS NULL,
      0,
      1) known_length_m,
  IF
    (registry_info.best_known_tonnage_gt IS NULL,
      0,
      1)known_tonnage_gt,
  IF
    (registry_info.best_known_engine_power_kw IS NULL,
      0,
      1) known_engine_power_kw,
  IF
    (best.best_crew_size = inferred.avg_inferred_crew_size_byyear
      AND NOT best.best_crew_size IS NULL,
      1,
      0) known_crew_size
  FROM
    `world-fishing-827.gfw_research.vi_ssvid_byyear_v20200801`),
  joined AS(
  SELECT
    *
  FROM
    known_info
  JOIN
    risk_predictions
  USING
    (mmsi,
      year))
SELECT
  year,
  COUNT(*) number_vessels,
  SUM(known_length_m) number_vessels_known_length,
  SUM(known_tonnage_gt) number_vessels_known_tonnage_gt,
  SUM(known_engine_power_kw) number_vessels_known_engine_power_kw,
  SUM(known_crew_size) number_vessels_known_crew_size,
  SUM(known_length_m)/COUNT(*) fraction_vessels_known_length,
  SUM(known_tonnage_gt)/COUNT(*) fraction_number_vessels_known_tonnage_gt,
  SUM(known_engine_power_kw)/COUNT(*) fraction_number_vessels_known_engine_power_kw,
  SUM(known_crew_size)/COUNT(*) fraction_number_vessels_known_crew_size
FROM
  joined
GROUP BY
  year
ORDER BY
  year"

known_vessel_info <- bq_project_query(gfw_project, sql) %>%
  bq_table_download(max_results = Inf)

write_csv(known_vessel_info,here::here("interim_data/s13_known_vessel_info.csv"))

```


\pagebreak

# Figures

```{r eval = TRUE}
# Read in cached bag performance
bag_performance <- read_csv(here::here("interim_data/s7_figure_s3_data.csv"))

# Here we choose the optimzed model
# Non-bagging version has standard error too large
# Stick with 5 bags to reduce variation
# Stick with under_ratio of 1 for simplest model
# Random forest has lowest standard deviation for modified f1, and has a higher recall
optimized_model <- tibble(model_type = "random-forest",
                          bagging = TRUE,
                          under_ratio = 1,
                          number_bags = 100)

cv_performance <- bag_performance %>% 
  mutate(bagging = ifelse(is.na(under_ratio),FALSE,TRUE)) %>%
  inner_join(optimized_model,by = c("model_type", "number_bags", "under_ratio","bagging"))

optimized_model$.threshold <- cv_performance$.threshold[1]

# Read in cached final predictions
predictions_figures <- read.csv(here::here("interim_data/s4_final_model_predictions.csv"),stringsAsFactors = FALSE) %>%
  as_tibble() %>% 
  mutate(Prediction = ifelse(class == 1,"Positive","Negative")) %>%
  mutate(Label = ifelse(offender == 0,"Unlabeled","Positive"))

# Pull in forced labor vessel database
fldb_data <-read_csv(here::here("raw_data/s3_suspected_forced_labor_database.csv"))

# Pull in spatial forced labor risk data
grouped_messages <- read.csv(here::here("interim_data/s5_figure_3_data.csv"))

# Pull in port data
port_data <- read_csv(here::here("interim_data/s6_figure_4_data.csv")) %>%
  filter(!is.na(port_iso3))

# For each port country, summarize if there were known offender visits and predicted high-risk visits
# This will determine if there were any visits by known offenders across the entire 2012-2018 timeframe
port_visit_summary <- port_data %>%
  group_by(port_iso3) %>%
  summarize(has_known_offender_visits = ifelse(sum(known_offender_visits,na.rm=TRUE)>0,TRUE,FALSE)) %>%
  ungroup()

# For remaining analysis, just look at 2018
port_data <- port_data %>%
  filter(year==2018) %>%
  left_join(port_visit_summary,by= c("port_iso3"))

# Read in cached cross-validation results from robustness checks
robustness_cv <- read.csv(here::here("interim_data/s9_robustness_cv.csv"),stringsAsFactors = FALSE) %>%
  mutate(year_assumption = as.character(year_assumption))

# Read in cached final results from robustness checks
robustness_predictions_figures <- read.csv(here::here("interim_data/s10_robustness_predictions_figures.csv"),stringsAsFactors = FALSE) %>%
  mutate(year_assumption = as.character(year_assumption)) %>%
  mutate(Country = countrycode(flag,"iso3c","country.name"))%>%
  # Use optimal threshold found above
  mutate(Prediction = ifelse(class == 1,"Positive","Negative")) %>%
  mutate(Label = ifelse(offender == 0,"Unlabeled","Positive"))

# Pull in summary of known vessel registry info
known_vessel_info <- read_csv(here::here("interim_data/s13_known_vessel_info.csv"))
```

## Figure 1: Training data model feature summary

```{r eval = params$generate_figures}
training_df_figure <- filtered_main_df %>%
  mutate(ais_type = ifelse(ais_type == "A",1,0))%>%
  dplyr::select(-year,-source_id,-fldb_vessel_id,-flag)


asinh_trans <- function(){
  scales::trans_new(name = 'asinh', transform = function(x) asinh(x), 
            inverse = function(x) sinh(x))
}

indicator_figure_data <- recipes::recipe(offender ~ ., data = head(training_df_figure)) %>%
  recipes::update_role(mmsi, new_role = "id variable") %>%
  recipes::update_role(gear, new_role = "id variable") %>%
  # Box-Cox transformation on all numeric
  recipes::step_BoxCox(all_numeric())%>%
  step_normalize(all_predictors()) %>%
  prep(training_df_figure) %>%
  juice() %>%
  pivot_longer(cols=c(-"mmsi",-"gear",-"offender"),names_to = "indicator") %>%
  mutate(gear = case_when(gear=="drifting_longlines" ~ "Longliner",
                          gear=="squid_jigger" ~ "Squid jigger",
                          TRUE ~ "Trawler")) %>%
    left_join(feature_lookup,by="indicator") %>%
  mutate(offender=ifelse(offender==1,"Positive","Unlabeled"))  %>%
  mutate(indicator_type = case_when(indicator_type =="directly_observed" ~ "Directly\nobserved",
                                    indicator_type =="gfw_fishing_model" ~ "GFW\nfishing\nalgorithm",
                                    indicator_type =="registry_or_gfw_vessel_model" ~ "Vessel\nregistry\nor GFW\nvessel\nalgorithm"))

indicator_figure <- indicator_figure_data %>%
  ggplot(aes(x = reorder(indicator_name,desc(indicator_name)),y=value,color=factor(offender))) +
  geom_boxplot(position=position_dodge(width=1),outlier.size = 0.1) +
  disco::scale_color_disco(palette = "vibrant", "Training data label",direction=1,alpha=1,
                           guide = guide_legend(reverse = TRUE) ) +
  coord_flip() +
  facet_grid_paginate(indicator_type~gear,drop=TRUE,space="free",scales="free_y") +
  #facet_col("indicator_type",scales="free_y",drop=TRUE,space="free") +
  #facet_grid(indicator_type~gear,scales="free_y") +
  scale_y_continuous(trans="asinh",breaks = scales::pretty_breaks(2)) +
    labs(
      x = "",
      y = "Box-Cox transformed, centered, and scaled\n vales (inverse hyperbolic sine scale)"
    ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1,size=8),
        legend.position = "bottom",
        legend.direction = "horizontal",
        strip.text.y.right = element_text(angle = 0),
        strip.background =element_rect(fill=NA))

indicator_figure

ggsave(here::here("output_figures/figure_1.png"),indicator_figure,width=8,height=8,device="png",dpi=300)
```

\pagebreak

## Figure 2 - Forced labor risk by fishing fleet

### Figure 2 using point estimates

```{r eval = TRUE}
flag_predictions_other <- predictions_figures %>%
  filter(class == 1) %>%
  group_by(Country,gear) %>%
  summarize(count_vessels = n_distinct(mmsi_anonymous)) %>%
  ungroup() %>%
  group_by(gear) %>%
  mutate(fraction = count_vessels / sum(count_vessels)) %>%
  mutate(Other = ifelse(fraction<0.05,TRUE,FALSE))
```

```{r eval = params$generate_figures}
vessels_fig_total <- predictions_figures  %>%
  filter(class == 1) %>%
  left_join(flag_predictions_other,by=c("Country","gear")) %>%
  mutate(Country = ifelse(Other,"Other",Country))%>%
  mutate(gear = case_when(gear=="drifting_longlines" ~ "Longliner",
                          gear=="squid_jigger" ~ "Squid jigger",
                          TRUE ~ "Trawler")) %>%
  group_by(Country,gear,year) %>%
  summarize(`Number of vessels` = n()) %>%
  ungroup() %>%
  ggplot(aes(x = year, y = `Number of vessels`, fill = Country)) +
  geom_bar(stat = "identity", color = "black",size=0.25) +
  #coord_flip() +
  labs(x="",title="(A) Number of high-risk vessels",y="") +
  theme_bw() +
  disco::scale_fill_disco(palette = "rainbow", "Flag") +
  facet_grid(.~gear)+
  scale_y_continuous(labels=scales::comma)+ 
  scale_x_continuous(breaks = unique(predictions_figures$year)) +
  theme(strip.background =element_rect(fill=NA),
        axis.text.x = element_blank(),
        panel.grid.minor = element_blank())

vessels_fig_percentage <- predictions_figures %>%
  group_by(year,gear) %>%
  summarize(fraction_high_risk = sum(class) / n())%>%
  ungroup() %>%
  mutate(gear = case_when(gear=="drifting_longlines" ~ "Longliner",
                          gear=="squid_jigger" ~ "Squid jigger",
                          TRUE ~ "Trawler")) %>%
  ggplot(aes(x = year, y = fraction_high_risk)) +
  geom_bar(stat="identity",color="black") +
  facet_grid(.~gear) +
  theme_bw()+
  scale_y_continuous(labels=scales::percent,limits = c(0,1))+ 
  scale_x_continuous(breaks = unique(predictions_figures$year),
                   labels = unique(predictions_figures$year)) +
  theme(strip.background =element_rect(fill=NA),
        axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.minor = element_blank())+
  labs(x="",title="(B) Percentage of total vessels that are high-risk",y="")

legend <- get_legend(
  # create some space to the left of the legend
  vessels_fig_total
)

vessels_fig <- cowplot::plot_grid(plot_grid(vessels_fig_total+ theme(legend.position="none"),
                             vessels_fig_percentage,
                             align = "v", 
                             ncol = 1),
                   legend,
                   ncol=2,
                   rel_widths = c(4,1))  
vessels_fig
ggsave(here::here("output_figures/figure_2.png"),vessels_fig,width=7.5,height=5,device="png",dpi=300)
```

\pagebreak

### Figure 2 using range estimates from robustness checks

```{r eval = params$generate_figures}
vessels_fig_data_summary_other <- robustness_predictions_figures %>%
  filter(include_vessel_characteristics) %>%
  filter(class == 1) %>%
  group_by(Country,gear) %>%
  summarize(count_vessels_years = n())%>%
  group_by(gear) %>%
  mutate(fraction = count_vessels_years / sum(count_vessels_years)) %>%
  ungroup() %>%
  mutate(Other = ifelse(fraction<0.05,TRUE,FALSE))  %>%
  dplyr::select(Country,gear,Other)

vessels_fig_data_summary_combined <- robustness_predictions_figures %>%
  filter(include_vessel_characteristics) %>%
  filter(class == 1) %>%
  left_join(vessels_fig_data_summary_other,by=c("Country","gear")) %>%
  mutate(Country = ifelse(Other,"Other",Country)) %>%
  group_by(Country,gear,year,year_assumption,include_vessel_characteristics) %>%
  summarize(count_vessels = n_distinct(mmsi_anonymous)) %>%
  ungroup() %>%
  group_by(Country,gear,year) %>%
  summarize(count_vessels_average = mean(count_vessels,na.rm=TRUE),
            count_vessels_min = min(count_vessels,na.rm=TRUE),
            count_vessels_max = max(count_vessels,na.rm=TRUE)) %>%
  ungroup() %>%
  group_by(gear) %>%
  complete(Country,year,fill = list(count_vessels_min=0,
                                                  count_vessels_max=0,
                                                  count_vessels_average=0)) %>%
  ungroup()

vessels_fig_total <- vessels_fig_data_summary_combined %>%
  mutate(gear = case_when(gear=="drifting_longlines" ~ "Longliner",
                          gear=="squid_jigger" ~ "Squid jigger",
                          TRUE ~ "Trawler")) %>%
  ggplot(aes(year)) + 
  geom_ribbon(aes(ymin=count_vessels_min, ymax=count_vessels_max,fill=Country,color=Country),alpha=0.5,size=0.25)+
  geom_line(aes(y=count_vessels_average,color=Country)) +
  labs(x="",title="(A) Number of high-risk vessels",y="") +
  theme_bw() +
  disco::scale_fill_disco(palette = "rainbow", "Flag") +
  disco::scale_color_disco(palette = "rainbow", "Flag") +
  facet_grid(.~gear)+
  scale_y_continuous(labels=scales::comma)+ 
  scale_x_continuous(breaks = unique(predictions_figures$year)) +
  theme(strip.background =element_rect(fill=NA),
        axis.text.x = element_blank(),
        panel.grid.minor = element_blank())


vessels_fig_percentage <- robustness_predictions_figures %>%
  group_by(gear,year,year_assumption,include_vessel_characteristics) %>%
  summarize(fraction_high_risk = sum(class) / n())%>%
  ungroup() %>%
  group_by(year,gear) %>%
  summarize(fraction_high_risk_average = mean(fraction_high_risk,na.rm=TRUE),
            fraction_high_risk_min = min(fraction_high_risk,na.rm=TRUE),
            fraction_high_risk_max = max(fraction_high_risk,na.rm=TRUE))%>%
  ungroup() %>%
  mutate(gear = case_when(gear=="drifting_longlines" ~ "Longliner",
                          gear=="squid_jigger" ~ "Squid jigger",
                          TRUE ~ "Trawler")) %>%
  ggplot(aes(year)) +
  geom_ribbon(aes(ymin=fraction_high_risk_min, ymax=fraction_high_risk_max),alpha=0.5,size=0.25,color="black") +
  geom_line(aes(y=fraction_high_risk_average)) +
  facet_grid(.~gear) +
  theme_bw()+
  scale_y_continuous(labels=scales::percent,limits = c(0,1))+ 
  scale_x_continuous(breaks = unique(predictions_figures$year),
                     labels = unique(predictions_figures$year)) +
  theme(strip.background =element_rect(fill=NA),
        axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.minor = element_blank())+
  labs(x="",title="(B) Percentage of total vessels that are high-risk",y="")

legend <- get_legend(
  # create some space to the left of the legend
  vessels_fig_total
)

vessels_fig <- cowplot::plot_grid(plot_grid(vessels_fig_total+ theme(legend.position="none"),
                                            vessels_fig_percentage,
                                            align = "v", 
                                            ncol = 1),
                                  legend,
                                  ncol=2,
                                  rel_widths = c(4,1))  
vessels_fig

ggsave(here::here("output_figures/figure_2_robust.png"),vessels_fig,width=7.5,height=5,device="png",dpi=300)

```


\pagebreak

## Figure 3 - Spatial forced labor risk

```{r eval = params$generate_figures}
world_land <- rworldmap::getMap(resolution = "low") %>%
  st_as_sf()

map_palette <- "inferno"
map_palette_begin <- 0.2
na_color <- viridis::viridis(n=5,option=map_palette,begin=map_palette_begin)[1]

pal <- c(viridis::inferno(n = 8))[c(3,5:8)]
pal <- c("midnightblue",viridis::inferno(n = 7)[c(3:7)])

map_figure_rel <-   grouped_messages %>%
  filter(!is.na(gear))%>%
  mutate(gear = case_when(gear=="drifting_longlines" ~ "(A) Longliner",
                          gear=="squid_jigger" ~ "(B) Squid jigger",
                          TRUE ~ "(C) Trawler")) %>%
  ggplot() +
  geom_tile(aes(x = lon_bin, y = lat_bin, fill = fraction_at_risk_fishing_kW_hours,color=fraction_at_risk_fishing_kW_hours)) +
  geom_sf(data = world_land, fill = "grey45", color = "grey45") +
  scale_fill_gradientn(name = "Percentage\nfishing kW-hours\nhigh-risk", na.value = pal[1], values = c(0,0.1,.25,0.5,0.75,1),labels=paste0(seq(0,1,.25)*100,"%"),breaks=seq(0,1,.25),colors=pal)  +
  theme_minimal() +
  theme(panel.background = element_rect(fill="black"),
        panel.grid.major = element_line(colour = "black"),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        text = element_text(size=15),
        legend.direction = "vertical"
  ) +
  labs(
    x = "",
    y = "")+ 
  ylim(c(-70, NA)) +
  scale_color_gradientn(name = "Percentage\nfishing kW-hours\nhigh-risk", na.value = pal[1], values = c(0,0.1,.25,0.5,0.75,1),guide=FALSE,labels=paste0(seq(0,1,.25)*100,"%"),breaks=seq(0,1,.25),colors=pal)  +
  facet_wrap(.~gear,ncol=1)

map_figure_rel
ggsave(here::here("output_figures/figure_3.png"),map_figure_rel,width=7.5,height=7.5,device="png",dpi=300)                                    
```

\pagebreak

## Figure 4: Port visits by high-risk vessels

```{r eval = params$generate_figures}
world_land_ports <- world_land %>% 
  as_tibble() %>%
  mutate(port_iso3 = as.character(ISO3.1)) %>%
  dplyr::select(geometry,port_iso3) %>%
  inner_join(port_data %>%
               filter(year==2018),by="port_iso3") %>%
  st_as_sf()



pal <- c("midnightblue",viridis::inferno(n = 7)[c(3:7)])

port_map_figure_rel <-   world_land_ports %>%
  filter(!is.na(gear))%>%
  mutate(gear = case_when(gear=="drifting_longlines" ~ "(A) Longliner",
                          gear=="squid_jigger" ~ "(B) Squid jigger",
                          TRUE ~ "(C) Trawler")) %>%
  ggplot() +
  geom_sf(data = world_land, fill = "grey45", color = "grey45") +
  geom_sf(aes(
    fill = fraction_high_risk_visits,
    color = has_known_offender_visits
  ),
    size=0.1) +
  scale_fill_gradientn(name = "Percentage\nport visits\nhigh-risk", na.value = pal[1], values = c(0,0.1,.25,0.5,0.75,1),labels=paste0(seq(0,1,.25)*100,"%"),breaks=seq(0,1,.25),colors=pal)  +
  scale_color_manual("Has known positive\nport visits",
                     values = c("grey40","white")) +
  theme_minimal() +
  theme(panel.background = element_rect(fill="black"),
        panel.grid.major = element_line(colour = "black"),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        text = element_text(size=15),
        legend.direction = "vertical",
        legend.key = element_rect(fill = "black")
  ) +
  labs(
    x = "",
    y = ""
  ) + 
  ylim(c(-70, NA)) +
  facet_wrap(.~gear,ncol=1)+ 
  guides(color = guide_legend(override.aes = list(size = 1,
                                                  fill = "black")))

#port_map_figure <- cowplot::plot_grid(port_map_figure_abs,port_map_figure_rel)
port_map_figure_rel

ggsave(here::here("/output_figures/figure_4.png"),port_map_figure_rel,width=7.5,height=7.5,device="png",dpi=300)      
```

\pagebreak

## Figure S1 - Positive vessel cases

```{r eval = params$generate_figures}
# Make figure summarizing ILO indicators

positive_vessels <- predictions_figures %>%
  filter(offender == 1) %>%
  dplyr::select(mmsi_anonymous,fldb_vessel_id,year,offender)

# Summarize the number and fraction of forced labor vessels in operation during each number
still_in_operation_stats <- predictions_figures %>%
  filter(!is.na(fldb_vessel_id)) %>%
  group_by(year) %>%
  summarize(count_in_operation = n(),
            fraction_in_operation = n()/nrow(positive_vessels))

operation_data <- predictions_figures %>%
  as_tibble() %>%
  filter(!is.na(fldb_vessel_id))%>% 
  dplyr::select(fldb_vessel_id,name=year,offender,class,mmsi_anonymous)%>%
  mutate(mmsi_anonymous=as.factor(mmsi_anonymous))%>%
  mutate(offender=as.factor(offender),
         class=as.factor(class),
         name = as.factor(name))%>%
  mutate(fldb_vessel_id = as.character(fldb_vessel_id))%>%
  mutate(indicator_type = "operation_status")

ilo_data <- fldb_data %>%
  dplyr::select(fldb_vessel_id,forced_labor_indicator)%>%
  separate_rows(forced_labor_indicator,sep = ' \\| ') %>%
  mutate(forced_labor_indicator = case_when(forced_labor_indicator == "Abusive working and living conditons" ~ "Abusive working and living conditions",
                                            forced_labor_indicator == "Witholding of wages" ~ "Withholding of wages",
                                            TRUE ~ forced_labor_indicator)) %>%
  mutate(fldb_vessel_id = as.character(fldb_vessel_id)) %>%
  rename(name = forced_labor_indicator)%>%
  mutate(indicator_type = "ilo_indicator") %>%
  mutate(offender=as.factor(1),
         class=as.factor(1))

case_data <- fldb_data %>%
  dplyr::select(fldb_vessel_id,eyewitness_account,official_investigation,non_official_investigations,arrests_made,charges_filed,conviction_made,penalties_sanctioned) %>%
  rename(`Penalties sanctioned` = penalties_sanctioned,
         `Eyewitness account` = eyewitness_account,
         `Official investigation` = official_investigation,
         `Non-official investigation` = non_official_investigations,
         `Arrests made` = arrests_made,
         `Charges filed` = charges_filed,
         `Conviction made` = conviction_made) %>%
  pivot_longer(cols = -fldb_vessel_id) %>%
  filter(!is.na(value))  %>%
  mutate(fldb_vessel_id = as.character(fldb_vessel_id)) %>%
  mutate(indicator_type = "case_info") %>%
  dplyr::select(-value) %>%
  mutate(offender=as.factor(1),
         class=as.factor(1))

combined_case_data <- bind_rows(ilo_data,case_data,operation_data)

# Summarize data by indicator, for organizing figure
ilo_summary_data <- ilo_data %>%
  group_by(name) %>%
  summarize(count = n()) %>%
  ungroup() %>%
  arrange(count)
# Summarize data by vessel, for organizing figure
ilo_summary_vessel<- ilo_data %>%
  group_by(fldb_vessel_id) %>%
  summarize(count = n()) %>%
  ungroup() %>%
  arrange(-count)

# Summarize data by case info, for organizing figure
case_summary_data <- rev(c("Eyewitness account",
                           "Non-official investigation",
                       "Official investigation",
                       "Arrests made",
                       "Charges filed",
                       "Conviction made",
                       "Penalties sanctioned"))

# Define factors for figure
summary_data <- c(ilo_summary_data$name,case_summary_data,rev(seq(2012,2018)))

ilo_indicator_fig <- combined_case_data %>%
  mutate(class = ifelse(class=="1","Positive","Negative") %>% fct_relevel("Positive")) %>%
  mutate(offender = ifelse(offender=="1","Positive","Not included")%>% fct_relevel("Positive")) %>%
  mutate(name = fct_relevel(name,summary_data))%>%
  mutate(fldb_vessel_id = fct_relevel(fldb_vessel_id,ilo_summary_vessel$fldb_vessel_id)) %>%
  mutate(indicator_type = case_when(indicator_type=="case_info"~"(B) Case status information",
                                    indicator_type=="ilo_indicator" ~ "(A) ILO forced labor indicator",
                                    TRUE ~ "(C) Vessel operation status and model classification")) %>%
  mutate(indicator_type = fct_relevel(indicator_type,"(A) ILO forced labor indicator")) %>%
  ggplot(aes(x=fldb_vessel_id,y=name,fill=interaction(class,indicator_type),color=interaction(offender,indicator_type))) +
  facet_col("indicator_type",scales="free_y",drop=TRUE,space="free") +
  geom_count(shape = 21,stroke=1.1) +
  theme_bw() +
  theme(axis.text.x = element_blank(),
        legend.position = "bottom",
        strip.background = element_blank(),
        strip.text = element_text(hjust=0,angle = 0)) +
  labs(x = "Reported vessel case",y="") +
  scale_color_manual("(C) Training\ndata label",values = c("black","black","red","black"),
                     breaks = c("Positive.(C) Vessel operation status and model classification","Not included.(C) Vessel operation status and model classification"),
                     labels = c("Positive","Not included")) +
  scale_fill_manual("(C) Model\nclassification",values = c("black","black","gray30","gray80"),
                     breaks = c("Positive.(C) Vessel operation status and model classification","Negative.(C) Vessel operation status and model classification"),
                     labels = c("Positive","Negative")) +
  guides(size = FALSE,
         fill = guide_legend(override.aes = list(size=4),nrow=2),
         color = guide_legend(override.aes = list(size=4),nrow=2,order = 1))

ilo_indicator_fig

ggsave(here::here("output_figures/figure_s1.png"),ilo_indicator_fig,width=7.5,height=7.5,device="png",dpi=300)
```

\pagebreak

## Figure S3 - Cross-validation performance

```{r eval = params$generate_figures}
# Which bags to show in the figure
bags_to_show <- c(1,10,50,100)
cv_performance_fig <- bag_performance %>%
  filter(!is.na(under_ratio) | number_bags ==1) %>%
  mutate(number_bags = paste0("Bags: ",number_bags) %>%
           fct_relevel(paste0("Bags: ",bags_to_show))) %>%
mutate(under_ratio = ifelse(is.na(under_ratio),"B",under_ratio) %>%
           fct_relevel("B")) %>%
  mutate(model_type=ifelse(model_type=="random-forest","Random forest","Support vector\nmachine")) %>%
  mutate(error_min = pmax(mean_performance-sd_performance,0),
         error_max = ifelse(.metric=="recall",pmin(mean_performance+sd_performance,1),mean_performance+sd_performance)) %>%
#  filter(.metric %in% c("recall","modified_f1")) %>% 
    mutate(.metric = case_when(.metric=="recall"~"Recall",
                               .metric=="modified_f1"~"Modified F1",
                               TRUE~"Detection\nprevalence")) %>%
  mutate(.metric = fct_relevel(.metric,"Recall","Detection\nprevalence")) %>%
  ggplot(aes(x = factor(under_ratio),y=mean_performance,color=model_type)) + 
  geom_point(position=position_dodge(width=0.75)) +
  geom_errorbar(aes(ymin=error_min, ymax=error_max),position=position_dodge(width=0.75),width=0.5) + 
  facet_grid(.metric~number_bags,scales="free_y",switch="y") +
  labs(x = "Downsampling ratio",
       y = "Mean\nacross\nfolds")+ 
  theme_bw() +
  theme(strip.background =element_rect(fill=NA),
        axis.title.y = element_text(angle=0,vjust=0.5),
        strip.text.y.left = element_text(angle=0,vjust=0.5)) +
  disco::scale_color_disco("Model type")

cv_performance_fig

ggsave(here::here("output_figures/figure_s3.png"),cv_performance_fig,width=7.5,height=7.5,device="png",dpi=300)
```

\pagebreak

## Figure S4: Classification by training label

```{r  eval = params$generate_figures}
n_fun <- function(x){
  return(data.frame(y = max(x) + 0.05, label = paste0("n = ",prettyNum(length(x),big.mark=","))))
}

class_fig <- predictions_figures  %>%
  ggplot(aes(x=Prediction,y=prediction,fill=Label)) + 
  geom_boxplot(position = position_dodge(width = 0.75)) + 
  coord_flip() + 
  geom_hline(yintercept = optimized_model$.threshold,linetype=2) +
  labs(y = "Model risk score",
       x = "Model\nclassification")+
    stat_summary(fun.data = n_fun, geom = "label",position = position_dodge(width = 0.75),show.legend = FALSE) +
  ylim(c(0,1)) +
  disco::scale_fill_disco(palette = "vibrant", "Training data\nlabel",direction=1,alpha=1,
                           guide = guide_legend(reverse = TRUE) ) +
  theme_bw() +
  theme(axis.title.y = element_text(angle=0,vjust=0.5))

class_fig

ggsave(here::here("output_figures/figure_s4.png"),class_fig,width=7.5,height=3.5,device="png",dpi=300)
```

\pagebreak

## Figure S5: Variable importance

```{r eval = params$generate_figures}
importance_fig <- read_csv(here::here("interim_data/s8_figure_s5_data.csv")) %>%
  ggplot(aes(x = reorder(indicator_name,Importance), y = Importance)) +
  geom_bar(stat = "identity",color="black") +
  coord_flip() +
  labs(x = "",
       y = "Mean importance across bags") +
  theme_bw() +
  theme(panel.grid.minor = element_blank())

importance_fig

ggsave(here::here("output_figures/figure_s5.png"),importance_fig,width=7.5,height=5,device="png",dpi=300)
```

\pagebreak

# Figure S6 - Summary of known vessel registry information

```{r eval = params$generate_figures}
known_vessel_info_fig <- known_vessel_info %>%
  mutate(year = as.character(year)) %>%
  pivot_longer(-year) %>%
  filter(name %in% c("fraction_vessels_known_length",
                     "fraction_number_vessels_known_crew_size",
                     "fraction_number_vessels_known_tonnage_gt",
                     "fraction_number_vessels_known_engine_power_kw")) %>%
  mutate(name = case_when(name=="fraction_vessels_known_length"~"Percentage of vessels with registry length",
                          name=="fraction_number_vessels_known_crew_size"~"Percentage of vessels with registry crew size",
                          name=="fraction_number_vessels_known_tonnage_gt"~"Percentage of vessels with registry tonnage",
                          name=="fraction_number_vessels_known_engine_power_kw"~"Percentage of vessels with registry engine power")) %>%
  ggplot(aes(x=year,y=value)) +
  geom_bar(stat="identity",color="black") +
  facet_wrap(name~.,ncol=1,scales="free_y") +
  scale_y_continuous(labels = scales::percent) +
  theme_bw() +
  labs(x="",
       y="") +
  theme(strip.background = element_blank())

known_vessel_info_fig

ggsave(here::here("output_figures/figure_s6.png"),known_vessel_info_fig,width=7.5,height=5,device="png",dpi=300)

```


\pagebreak

## Figure S7 - Cross-validation results from robustness checks

```{r eval = params$generate_figures}
robustness_cv_fig <- robustness_cv %>%
  mutate(error_min = pmax(mean_performance-sd_performance,0),
         error_max = ifelse(.metric=="recall",
                            pmin(mean_performance+sd_performance,1),
                            mean_performance+sd_performance))%>%
  mutate(.metric = case_when(.metric=="recall"~"Recall",
                             .metric=="modified_f1"~"Modified F1",
                             TRUE~"Detection\nprevalence")) %>%
  mutate(include_vessel_characteristics = ifelse(include_vessel_characteristics,"Yes","No") %>%
           fct_relevel("Yes")) %>%
  ggplot(aes(x = year_assumption,y=mean_performance,color=include_vessel_characteristics)) +
  geom_point(position=position_dodge(width=0.75)) +
  geom_errorbar(aes(ymin=error_min, ymax=error_max),position=position_dodge(width=0.75),width=0.5) + 
  facet_grid(.metric~.,scales="free_y",switch="y") +
  labs(x = "Positive training data set label year assumption",
       y = "Mean\nacross\nfolds")+ 
  theme_bw() +
  theme(strip.background =element_rect(fill=NA),
        axis.title.y = element_text(angle=0,vjust=0.5),
        strip.text.y.left = element_text(angle=0,vjust=0.5)) +
  disco::scale_color_disco("Include\nvessel\ncharacteristics",palette="muted") +
  ylim(c(0,NA))

robustness_cv_fig

ggsave(here::here("output_figures/figure_s7.png"),robustness_cv_fig,width=7.5,height=5,device="png",dpi=300)

```

\pagebreak

## Figure S8 - Final model results from robustness checks

```{r eval = TRUE}
robustness_final <- robustness_predictions_figures %>%
  group_by(year_assumption,include_vessel_characteristics) %>%
  nest() %>%
  mutate(results = map(data,function(x){
    
    tmp_pred <- x
    
    n_predicted_positive_vessel_years <- tmp_pred %>%
      filter(Prediction == "Positive") %>%
      nrow()
    
    n_predicted_positive_vessel_years_new <- tmp_pred %>%
      filter(Prediction == "Positive" & Label == "Unlabeled") %>%
      nrow()
    
    fraction_positive_vessel_years <- n_predicted_positive_vessel_years / nrow(tmp_pred)
    
    
    n_predicted_positive_vessels <- tmp_pred %>%
      filter(Prediction == "Positive") %>%
      distinct(mmsi_anonymous) %>%
      nrow()
    
    fraction_positive_vessels <- n_predicted_positive_vessels / length(unique(tmp_pred$mmsi_anonymous))
    
    n_positive_crew <- tmp_pred %>%
      filter(Prediction == "Positive") %>%
      distinct(mmsi_anonymous,crew_size) %>%
      .$crew_size %>%
      sum()
    
    correct_positives <- tmp_pred %>%
      filter(Prediction == "Positive" & Label == "Positive") %>%
      nrow()
    
    fraction_correct_positives <- correct_positives / (tmp_pred %>%
                                                         filter( Label == "Positive") %>%
                                                         nrow())
    
    riskiest_gears <- tmp_pred %>%
      group_by(gear,class) %>%
      summarize(count = n()) %>%
      ungroup() %>%
      pivot_wider(names_from = "class",values_from="count") %>%
      mutate(fraction_risky = `1` / (`1` + `0`)) %>%
      rename(low_risk = `0`,
             high_risk = `1`)
    
    riskiest_fleets <-tmp_pred  %>%
      filter(class == 1) %>%
      group_by(mmsi_anonymous,Country,gear,year) %>%
      summarize(crew_size = mean(crew_size)) %>%
      ungroup() %>%
      group_by(Country,gear) %>%
      summarize(`Number of vessels` = n(),
                `Number of crew` = sum(crew_size)) %>%
      ungroup() %>%
      gather("indicator","count",-gear,-Country) %>%
      mutate(indicator = fct_relevel(indicator,c("Number of vessels","Number of crew"))) %>%
      filter(indicator == "Number of vessels") %>%
      arrange(desc(count)) %>%
      slice(1:5)

    return(tibble(n_predicted_positive_vessel_years = n_predicted_positive_vessel_years,
                  n_predicted_positive_vessels = n_predicted_positive_vessels,
                  n_predicted_positive_vessel_years_new = n_predicted_positive_vessel_years_new,
                  fraction_positive_vessels = fraction_positive_vessels,
                  fraction_positive_vessel_years = fraction_positive_vessel_years,
                  n_positive_crew = n_positive_crew,
                  fraction_correct_positives = fraction_correct_positives,
                  riskiest_gears = list(riskiest_gears),
                  riskiest_fleets = list(riskiest_fleets)))
  })) %>%
  ungroup() %>%
  dplyr::select(-data)

robustness_gears <- robustness_final %>%
  unnest(results) %>%
  dplyr::select(year_assumption,include_vessel_characteristics,riskiest_gears) %>%
  unnest(riskiest_gears)

robustness_fleets <- robustness_final %>%
  unnest(results) %>%
  dplyr::select(year_assumption,include_vessel_characteristics,riskiest_fleets) %>%
  unnest(riskiest_fleets)

robustness_final <- robustness_final  %>%
  unnest(results) %>%
  dplyr::select(-riskiest_gears,-riskiest_fleets)
```

```{r eval = params$generate_figures}
robustness_final_fig <- robustness_final%>%
  dplyr::select(-n_predicted_positive_vessel_years_new) %>%
  rename(`Fraction of correctly\nidentified true positives` = fraction_correct_positives,
         `Fraction of vessels\nidentified as positives` = fraction_positive_vessels,
         `Fraction of vessel-years\nidentified as positives` = fraction_positive_vessel_years,
         `Number of vessels\nidentified as positives` = n_predicted_positive_vessels,
         `Number of vessel-years\nidentified as positives` = n_predicted_positive_vessel_years,
         `Number of crew\nworking on\npositive vessels` = n_positive_crew) %>%
  pivot_longer(-c(year_assumption,include_vessel_characteristics)) %>%
  mutate(include_vessel_characteristics = ifelse(include_vessel_characteristics,"Yes","No") %>%
           fct_relevel("Yes")) %>%
  ggplot(aes(x = year_assumption,y=value,fill=include_vessel_characteristics)) +
  geom_bar(stat = "identity",position=position_dodge(width=1),color="black") +
  facet_grid(name~.,scales="free_y",switch="y") +
  labs(x = "Positive training data set label year assumption",
       y = "")+ 
  theme_bw() +
  theme(strip.background =element_rect(fill=NA),
        axis.title.y = element_text(angle=0,vjust=0.5),
        strip.text.y.left = element_text(angle=0,vjust=0.5)) +
  disco::scale_fill_disco("Include\nvessel\ncharacteristics",palette="muted") +
  scale_y_continuous(labels=scales::comma,limits = c(0,NA))

robustness_final_fig

ggsave(here::here("output_figures/figure_s8.png"),robustness_final_fig,width=7.5,height=7.5,device="png",dpi=300)

```

\pagebreak

# Statistics

## Using base model assumptions

```{r eval = TRUE}
# What is the number of unique high-risk vessels (vessels that were high-risk during at least 1 year)?
number_high_risk_vessels <- predictions_figures %>%
    filter(class ==1) %>%
    .$mmsi_anonymous %>% unique() %>% length()

# What is the fraction of unique vessels that were high-risk during at least 1 year?
fraction_high_risk_vessels <- number_high_risk_vessels /
  (predictions_figures %>%
    .$mmsi_anonymous %>% unique() %>% length())

# What is the number of potentially affected crew that were on high-risk vessels?
number_affected_crew <- predictions_figures %>%
  filter(class ==1) %>%
  group_by(mmsi_anonymous) %>%
  summarize(mean_crew = mean(crew_size,na.rm=TRUE)) %>%
  ungroup() %>%
  .$mean_crew %>%
  sum()

n_predicted_positive_vessel_years <- predictions_figures %>%
  filter(Prediction == "Positive") %>%
  nrow()

n_predicted_positive_vessel_years_new <- predictions_figures %>%
  filter(Prediction == "Positive" & Label == "Unlabeled") %>%
  nrow()

fraction_positive_vessel_years <- n_predicted_positive_vessel_years / nrow(predictions_figures)

correct_positives <- predictions_figures %>%
  filter(Prediction == "Positive" & Label == "Positive") %>%
  nrow()

fraction_correct_positives <- correct_positives / (predictions_figures %>%
  filter( Label == "Positive") %>%
  nrow())

riskiest_gears <- predictions_figures %>%
  group_by(gear,class) %>%
  summarize(count = n()) %>%
  ungroup() %>%
  pivot_wider(names_from = "class",values_from="count") %>%
  mutate(fraction_risky = `1` / (`1` + `0`),
         percentage_risky = round(fraction_risky * 100))

riskiest_fleets <-predictions_figures  %>%
  filter(class == 1) %>%
  left_join(flag_predictions_other,by=c("Country","gear")) %>%
  mutate(Country = ifelse(Other,"Other",Country))%>%
  group_by(mmsi_anonymous,Country,gear,year) %>%
  summarize(crew_size = mean(crew_size)) %>%
  ungroup() %>%
  group_by(Country,gear) %>%
  summarize(`Number of vessels` = n(),
            `Number of crew` = sum(crew_size)) %>%
  ungroup() %>%
  gather("indicator","count",-gear,-Country) %>%
  mutate(indicator = fct_relevel(indicator,c("Number of vessels","Number of crew"))) %>%
  filter(indicator == "Number of vessels") %>%
  arrange(desc(count)) %>%
  slice(1:5) %>%
  mutate(gear = case_when(gear == "squid_jigger" ~ "squid jiggers",
                                    gear == "drifting_longlines" ~ "longliners",
                                    gear == "trawlers" ~ "trawlers")) %>% 
  mutate(statement = paste(Country, gear)) %>% 
  .$statement %>% 
  paste(collapse = ", ")
```

```{r eval = TRUE}
## Port statistics
# How many countries had visits by known offenders in the 2012-2018 timeframe?
port_countries_known_offenders <- port_data%>%
  filter(has_known_offender_visits) %>%
  .$port_iso3 %>%
  unique() %>%
  length()

# How many countries have high-risk visits in 2018, but no previous known offender visits
port_countries_high_risk_no_known_offenders <- port_data %>%
  filter(high_risk_visits>0 & !has_known_offender_visits) %>%
  .$port_iso3 %>%
  unique() %>%
  length()

# Which countries have high-risk visits in 2018
countries_at_risk <- port_data %>% filter(fraction_high_risk_visits >0) %>% 
  mutate(country = countrycode(port_iso3,"iso3c","country.name")) %>% distinct(country) %>% arrange(country)

# How many countries had high-risk visits in 2018
n_countries_at_risk <-  nrow(countries_at_risk)

# What is the fraction of all countries that had high-risk port visits in 2018
fraction_countries_high_risk_port_visits <- n_countries_at_risk / (port_data %>% filter(!is.na(gear)) %>% .$port_iso3 %>% unique() %>% length())

# Which countries that had ratified the PSMA had high-risk port visits in 2018
psma_countries_at_risk <- port_data %>% 
  filter(psma_country & fraction_high_risk_visits >0) %>% 
  mutate(country = countrycode(port_iso3,"iso3c","country.name")) %>% 
  distinct(country) %>% 
  arrange(country)

# How many countries that had ratified the PSMA had high-risk port visits in 2018
number_psma_countries_at_risk <- psma_countries_at_risk%>% 
  nrow()

```


The model correctly identifies `r round(fraction_correct_positives * 100)`% of positive vessel-years as being high-risk, while also identifying `r prettyNum(n_predicted_positive_vessel_years,big.mark=",")` total high-risk vessel-years (`r round(fraction_positive_vessel_years * 100)`% of the total vessel-years). 

`r prettyNum(number_high_risk_vessels,big.mark=",")` unique vessels were high-risk during at least one year (`r round(fraction_high_risk_vessels * 100)`% of the total unique vessels).

`r prettyNum(round(number_affected_crew),big.mark=",")` crew members were working on these boats and thus potential victims of forced labor during at least one year. 

`r riskiest_fleets` represent the five fisheries with the largest number of unique high-risk vessels.

While longliners have the largest number of high-risk vessel-years across years, squid jiggers have the highest percentage of high-risk vessels across all years (`r riskiest_gears %>% filter(gear=="squid_jigger") %>% .$percentage_risky`%), followed by longliners (`r riskiest_gears %>% filter(gear=="drifting_longlines") %>% .$percentage_risky`%) and trawlers (`r riskiest_gears %>% filter(gear=="trawlers") %>% .$percentage_risky`%). 

We also find that known positive vessels visited ports in `r port_countries_known_offenders` countries during the 2012-2018-time frame using our base model assumptions. 

In 2018 alone, model-identified high-risk vessels visited ports across `r n_countries_at_risk` developed and developing countries in 2018 (`r round(fraction_countries_high_risk_port_visits*100)`% of all visited countries for these gear types), including `r number_psma_countries_at_risk` Parties to the Port State Measures Agreement (Figure 4). The visited ports are predominantly in Asia, Africa, and South America, with notable exceptions being Canada, United States, New Zealand, and several European countries. 

`r port_countries_high_risk_no_known_offenders` of the countries visited by high-risk vessels in 2018 had not been visited by known positive vessels, which is reflective of our limited training data set but may also be reflective of the limited port oversight currently occurring in many countries. 

```{r eval = TRUE, results='asis'}
countries_at_risk %>% 
  kableExtra::kbl(caption = "Countries that were visited by high-risk vessels in 2018",longtable=TRUE)
```

```{r eval = TRUE, results='asis'}
psma_countries_at_risk %>% 
  kableExtra::kbl(caption = "Countries that had ratified the PSMA and were visited by high-risk vessels in 2018",longtable=TRUE)
```


## Using range of results from robustness checks

```{r eval = TRUE}
robustness_summary <- robustness_final %>%
  filter(include_vessel_characteristics) %>%
  pivot_longer(-c(year_assumption,include_vessel_characteristics)) %>%
  group_by(name) %>%
  summarize(min = min(value,na.rm=TRUE),
            max = max(value,na.rm=TRUE)) %>%
  ungroup() %>%
  mutate(range = ifelse(!str_detect(name,"fraction"),
                        paste0(prettyNum(round(min),big.mark=","),
                               " and ",
                               prettyNum(round(max),big.mark=",")),
                        paste0(round(min*100),
                               "% and ",
                               round(max*100),"%")))

robustness_gears_summary <- robustness_gears %>%
  filter(include_vessel_characteristics)%>%
  group_by(gear) %>%
  summarize(min = min(fraction_risky,na.rm=TRUE),
            max = max(fraction_risky,na.rm=TRUE)) %>%
  ungroup() %>%
  mutate(range = paste0(round(min*100),
                               "% and ",
                               round(max*100),"%"))

robustness_fleets_summary <- robustness_fleets%>%
  filter(include_vessel_characteristics) %>%
  group_by(Country,gear) %>%
  summarize(count = sum(count)) %>%
  ungroup() %>%
  arrange(desc(count))%>%
  mutate(gear = case_when(gear == "squid_jigger" ~ "squid jiggers",
                                    gear == "drifting_longlines" ~ "longliners",
                                    gear == "trawlers" ~ "trawlers")) %>% 
  mutate(statement = paste(Country, gear)) %>% 
  .$statement %>% 
  paste(collapse = ", ")
```

The model correctly identifies between `r robustness_summary %>% filter(name=="fraction_correct_positives") %>% .$range` of positive vessel-years as being high-risk, while also identifying between `r n_predicted_positive_vessel_years` total high-risk vessel-years (between `r robustness_summary %>% filter(name=="fraction_positive_vessel_years") %>% .$range` of the total vessel-years). 

Between `r robustness_summary %>% filter(name=="n_predicted_positive_vessels") %>% .$range` unique vessels were high-risk during at least one year (between `r robustness_summary %>% filter(name=="fraction_positive_vessels") %>% .$range` of the total unique vessels).

Between `r robustness_summary %>% filter(name=="n_positive_crew") %>% .$range` crew members were working on these boats and thus potential victims of forced labor during at least one year. 

Looking across all model assumptions, `r robustness_fleets_summary` represent the five fisheries with the largest number of unique high-risk vessels.

While longliners have the largest number of high-risk vessel-years across years, squid jiggers have the highest percentage of high-risk vessels across all years (between `r robustness_gears_summary %>% filter(gear=="squid_jigger") %>% .$range`), followed by longliners (between `r robustness_gears_summary %>% filter(gear=="drifting_longlines") %>% .$range`) and trawlers (between `r robustness_gears_summary %>% filter(gear=="trawlers") %>% .$range`). 